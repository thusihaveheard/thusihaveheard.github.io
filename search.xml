<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[centos7使用kubeadm安装k8s-1.11版本]]></title>
    <url>%2F2018%2F12%2F14%2Fcentos7%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s-1-11%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[官方地址：https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/ https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/ 实验架构：lab1: master 11.11.11.111lab2: node 11.11.11.112lab3: node 11.11.11.113 #cat /etc/redhat-releaseCentOS Linux release 7.4.1708 (Core) 如下操作在所有节点操作：安装 kubeadm, kubelet 和 kubectl配置源cat &lt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装yum install -y kubelet kubeadm kubectl ipvsadm 配置系统相关参数临时禁用selinux永久关闭 修改/etc/sysconfig/selinux文件设置sed -i ‘s/SELINUX=permissive/SELINUX=disabled/‘ /etc/sysconfig/selinuxsetenforce 0 临时关闭swap永久关闭 注释/etc/fstab文件里swap相关的行swapoff -a 开启forwardDocker从1.13版本开始调整了默认的防火墙规则禁用了iptables filter表中FOWARD链这样会引起Kubernetes集群中跨Node的Pod无法通信 iptables -P FORWARD ACCEPT 配置转发相关参数，否则可能会出错cat &lt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1vm.swappiness=0EOFsysctl –system 加载ipvs相关内核模块如果重新开机，需要重新加载modprobe ip_vsmodprobe ip_vs_rrmodprobe ip_vs_wrrmodprobe ip_vs_shmodprobe nf_conntrack_ipv4lsmod | grep ip_vs 配置启动kubelet配置kubelet使用国内pause镜像配置kubelet的cgroups获取docker的cgroupsDOCKER_CGROUPS=$(docker info | grep ‘Cgroup’ | cut -d’ ‘ -f3)echo $DOCKER_CGROUPScat &gt;/etc/sysconfig/kubelet&lt;&lt;EOFKUBELET_EXTRA_ARGS=”–cgroup-driver=$DOCKER_CGROUPS –pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1”EOF 启动systemctl daemon-reloadsystemctl enable kubelet &amp;&amp; systemctl start kubelet 如下操作在master节点操作配置master节点1.11 版本 centos 下使用 ipvs 模式会出问题参考 https://github.com/kubernetes/kubernetes/issues/65461 生成配置文件cat &gt;kubeadm-master.config&lt;&lt;EOFapiVersion: kubeadm.k8s.io/v1alpha2kind: MasterConfigurationkubernetesVersion: v1.11.0imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containersapi: advertiseAddress: 11.11.11.111 controllerManagerExtraArgs: node-monitor-grace-period: 10s pod-eviction-timeout: 10s networking: podSubnet: 10.244.0.0/16 kubeProxy: config:​ # mode: ipvs​ mode: iptablesEOF 提前拉取镜像如果执行失败 可以多次执行kubeadm config images pull –config kubeadm-master.config 初始化kubeadm init –config kubeadm-master.config 配置使用kubectlrm -rf $HOME/.kubemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 查看node节点kubectl get nodes 只有网络插件也安装配置完成之后，才能会显示为ready状态设置master允许部署应用pod，参与工作负载，现在可以部署其他系统组件如 dashboard, heapster, efk等kubectl taint nodes –all node-role.kubernetes.io/master- 配置使用网络插件下载配置mkdir flannel &amp;&amp; cd flannelwget https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml 修改配置此处的ip配置要与上面kubeadm的pod-network一致 net-conf.json: |​ {​ “Network”: “10.244.0.0/16”,​ “Backend”: {​ “Type”: “vxlan”​ }​ } 修改镜像image: registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel:v0.10.0-amd64 docker registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel:v0.10.0-amd64 quay.io/coreos/flannel:v0.10.0-amd64 如果Node有多个网卡的话，参考flannel issues 39701，https://github.com/kubernetes/kubernetes/issues/39701目前需要在kube-flannel.yml中使用–iface参数指定集群主机内网网卡的名称，否则可能会出现dns无法解析。容器无法通信的情况，需要将kube-flannel.yml下载到本地，flanneld启动参数加上–iface=​ containers:​ - name: kube-flannel​ image: registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel:v0.10.0-amd64​ command:​ - /opt/bin/flanneld​ args:​ - –ip-masq​ - –kube-subnet-mgr​ - –iface=eth1 启动kubectl apply -f kube-flannel.yml 查看kubectl get pods –namespace kube-systemkubectl get svc –namespace kube-system 如下操作在Node节点操作配置node节点加入集群此命令为初始化master成功后返回的结果kubeadm join 11.11.11.111:6443 –token ocj4qp.qzshbzjpv095e418 –discovery-token-ca-cert-hash sha256:9ea06d48a41289b538aadb2103bbe794b3d2cb70740e522bd97ac6ef129e11e6 测试kubectl run nginx –replicas=2 –image=nginx:alpine –port=80kubectl expose deployment nginx –type=NodePort –name=example-service-nodeportkubectl expose deployment nginx –name=example-service kubectl get deploykubectl get podskubectl get svckubectl describe svc example-service kubectl run curl –image=radial/busyboxplus:curl -i –ttynslookup kubernetesnslookup example-servicecurl example-service 10.96.100.22 为查看svc时获取到的clusteripcurl “10.96.100.22” 32223 为查看svc时获取到的 nodeporthttp://11.11.11.112:32058/http://11.11.11.113:32058/ 清理删除kubectl delete svc example-service example-service-nodeportkubectl delete deploy nginx curl 小技巧忘记初始master节点时的node节点加入集群命令怎么办简单方法kubeadm token create –print-join-command 第二种方法token=$(kubeadm token generate)kubeadm token create $token –print-join-command –ttl=0 安装dashboardwget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 将Service改成NodePort类型……spec: type: NodePort ports:​ - port: 443​ targetPort: 8443 selector:​ k8s-app: kubernetes-dashboard…… 将镜像修改 image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.8.3 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.8.3 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.8.3 k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.3 $ kubectl create -f kubernetes-dashboard.yaml我们创建一个admin用户并授予admin 角色绑定，使用下面的yaml文件创建admin用户并赋予他管理员权限，然后就可以通过token 登陆dashbaord，这种认证方式本质实际上是通过Service Account 的身份认证加上Bearer token请求 API server 的方式实现，参考 Kubernetes 中的认证。生成tokenhttps://blog.qikqiak.com/post/update-kubernetes-dashboard-more-secure/ $ cat &gt; admin.yaml&lt;&lt;EOFkind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: admin annotations:​ rbac.authorization.kubernetes.io/autoupdate: “true”roleRef: kind: ClusterRole name: cluster-admin apiGroup: rbac.authorization.k8s.iosubjects: kind: ServiceAccountname: adminnamespace: kube-system apiVersion: v1kind: ServiceAccountmetadata: name: admin namespace: kube-system labels:​ kubernetes.io/cluster-service: “true”​ addonmanager.kubernetes.io/mode: ReconcileEOF $ kubectl create -f admin.yaml 获取token第一种方法$ kubectl get secret -n kube-system|grep admin-tokenadmin-token-gtzqz kubernetes.io/service-account-token 3 14s$ kubectl get secret admin-token-d5jsg -o jsonpath={.data.token} -n kube-system |base64 -d会生成一串很长的base64后的字符串 第二种方法$ kubectl -n kube-system describe secret kubectl -n kube-system get secret|grep admin-token|cut -d &quot; &quot; -f1|grep “token:”|tr -s “ “|cut -d “ “ -f2 安装所需镜像master节点所需镜像registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver-amd64:v1.11.0registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager-amd64:v1.11.0registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler-amd64:v1.11.0registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.0registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1registry.cn-hangzhou.aliyuncs.com/google_containers/etcd-amd64:3.2.18registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.1.3 node节点所需镜像docker pull registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel:v0.10.0-amd64 &amp;&amp; \docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.0 &amp;&amp; \docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1 &amp;&amp; \docker pull quay.io/coreos/flannel:v0.10.0-arm &amp;&amp; \docker pull quay.io/coreos/flannel:v0.10.0-ppc64le &amp;&amp; \docker pull quay.io/coreos/flannel:v0.10.0-s390x 相关配置文件查看kubeadm配置$ kubeadm config view /etc/kubernetes/admin.conf/etc/kubernetes/kubelet.conf/etc/kubernetes/controller-manager.conf/etc/kubernetes/scheduler.conf 排错coredns不正常，参考：https://medium.com/@joatmon08/playing-with-kubeadm-in-vagrant-machines-part-2-bac431095706发现coredns不正常 $ kubectl get pod –all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEblog mysql-deploy-88dffb7cf-7lsf4 1/1 Running 0 24mblog wordpress-deploy-66bcc48bdb-5vgmv 0/1 Init:0/1 0 24mdefault curl-87b54756-6hxk6 1/1 Running 0 3hdefault nginx-5dbb4c75cd-5rkhg 1/1 Running 0 4hdefault nginx-5dbb4c75cd-mcbdm 1/1 Running 0 4hkube-system coredns-777d78ff6f-6l57g 0/1 CrashLoopBackOff 76 6hkube-system coredns-777d78ff6f-pzjhs 0/1 CrashLoopBackOff 76 6hkube-system etcd-lab1 1/1 Running 0 7hkube-system kube-apiserver-lab1 1/1 Running 0 7hkube-system kube-controller-manager-lab1 1/1 Running 0 7hkube-system kube-flannel-ds-hlmjr 1/1 Running 0 6hkube-system kube-flannel-ds-ksk79 1/1 Running 0 7hkube-system kube-flannel-ds-nvd8g 1/1 Running 0 6hkube-system kube-proxy-glpgs 1/1 Running 0 7hkube-system kube-proxy-nnb2n 1/1 Running 0 7hkube-system kube-proxy-pfxrn 1/1 Running 0 6hkube-system kube-scheduler-lab1 1/1 Running 0 7hkube-system kubernetes-dashboard-754f4d5f69-t7mcl 1/1 Running 0 6h查看日志，显示报错$ kubectl logs coredns-777d78ff6f-6l57g -n kube-systemError from server (NotFound): the server could not find the requested resource ( pods/log coredns-777d78ff6f-6l57g)$ kubectl get nodes lab2 -o yamlapiVersion: v1kind: Nodemetadata: annotations:​ flannel.alpha.coreos.com/backend-data: ‘{“VtepMAC”:”fe:28:b1:8d:81:ce”}’​ flannel.alpha.coreos.com/backend-type: vxlan​ flannel.alpha.coreos.com/kube-subnet-manager: “true”​ flannel.alpha.coreos.com/public-ip: 10.0.2.15​ kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock​ node.alpha.kubernetes.io/ttl: “0”​ volumes.kubernetes.io/controller-managed-attach-detach: “true” creationTimestamp: 2018-07-30T02:24:33Z labels:​ beta.kubernetes.io/arch: amd64​ beta.kubernetes.io/os: linux​ kubernetes.io/hostname: lab2 name: lab2 resourceVersion: “41316” selfLink: /api/v1/nodes/lab2 uid: b2481ea3-939f-11e8-93c1-525400ad3b43spec: podCIDR: 10.244.1.0/24status: addresses: address: 10.0.2.15type: InternalIP address: lab2type: Hostnameallocatable:cpu: “2”ephemeral-storage: “36190907537”hugepages-2Mi: “0”memory: 1780976Kipods: “110”capacity:cpu: “2”ephemeral-storage: 39269648Kihugepages-2Mi: “0”memory: 1883376Kipods: “110”conditions: lastHeartbeatTime: 2018-07-30T09:30:54ZlastTransitionTime: 2018-07-30T09:13:40Zmessage: kubelet has sufficient disk space availablereason: KubeletHasSufficientDiskstatus: “False”type: OutOfDisk lastHeartbeatTime: 2018-07-30T09:30:54ZlastTransitionTime: 2018-07-30T09:13:40Zmessage: kubelet has sufficient memory availablereason: KubeletHasSufficientMemorystatus: “False”type: MemoryPressure lastHeartbeatTime: 2018-07-30T09:30:54ZlastTransitionTime: 2018-07-30T09:13:40Zmessage: kubelet has no disk pressurereason: KubeletHasNoDiskPressurestatus: “False”type: DiskPressure lastHeartbeatTime: 2018-07-30T09:30:54ZlastTransitionTime: 2018-07-30T02:24:33Zmessage: kubelet has sufficient PID availablereason: KubeletHasSufficientPIDstatus: “False”type: PIDPressure lastHeartbeatTime: 2018-07-30T09:30:54ZlastTransitionTime: 2018-07-30T09:13:40Zmessage: kubelet is posting ready statusreason: KubeletReadystatus: “True”type: ReadydaemonEndpoints:kubeletEndpoint: Port: 10250images: names: docker.io/wordpress@sha256:7f8aa332e6c905d1cb6efc6632801e4c6b52d9a91e41a25a1de7668fb6f1a6da docker.io/wordpress:latestsizeBytes: 408103498 names: docker.io/mysql@sha256:aaba540cdd9313645d892f4f20573e8b42b30e5be71c054b7befed2f7da5f85b docker.io/mysql:5.7sizeBytes: 371941626 names: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64@sha256:4be24eb360668859f75b85829f99e006639683606d0fe077e47f4dea292439cd registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.0sizeBytes: 97772373 names: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:d929e48a87979279307111fd28a52272d3fac0ed1dc8f2f53a9489be45e5f2eb registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.1.3sizeBytes: 45587362 names: quay.io/coreos/flannel@sha256:88f2b4d96fae34bfff3d46293f7f18d1f9f3ca026b4a4d288f28347fcb6580ac quay.io/coreos/flannel:v0.10.0-amd64sizeBytes: 44598861 names: registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel@sha256:25e23320b5965ec8d5063ecf9f5a154372f6c230334dd11d76a0290184e789be registry.cn-shanghai.aliyuncs.com/gcr-k8s/flannel:v0.10.0-amd64sizeBytes: 44598861 names: docker.io/nginx@sha256:23e4dacbc60479fa7f23b3b8e18aad41bd8445706d0538b25ba1d575a6e2410b docker.io/nginx:alpinesizeBytes: 18638463 names: docker.io/radial/busyboxplus@sha256:a68c05ab1112fd90ad7b14985a48520e9d26dbbe00cb9c09aa79fdc0ef46b372 docker.io/radial/busyboxplus:curlsizeBytes: 4233788 names: docker.io/busybox@sha256:d21b79794850b4b15d8d332b451d95351d14c951542942a816eea69c9e04b240 docker.io/busybox:latestsizeBytes: 1162745 names: registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64@sha256:759c3f0f6493093a9043cc813092290af69029699ade0e3dbe024e968fcb7cca registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1sizeBytes: 742472nodeInfo:architecture: amd64bootID: 4c547d33-3e71-4ab6-94bc-a9867ae6fb2fcontainerRuntimeVersion: docker://1.13.1kernelVersion: 3.10.0-693.11.6.el7.x86_64kubeProxyVersion: v1.11.1kubeletVersion: v1.11.1machineID: 37db00ab394b4b99a870185d3a95d0a1operatingSystem: linuxosImage: CentOS Linux 7 (Core)systemUUID: 37DB00AB-394B-4B99-A870-185D3A95D0A1 发现节点IP地址不正常…………status: addresses: address: 10.0.2.15type: InternalIP address: lab2type: Hostname…………kubectl get pod –all-namespaces -owideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system coredns-777d78ff6f-27tv7 0/1 CrashLoopBackOff 6 9m lab3kube-system coredns-777d78ff6f-b7j8w 0/1 CrashLoopBackOff 7 16m lab2kube-system etcd-lab1 1/1 Running 0 12m 11.11.11.111 lab1kube-system kube-apiserver-lab1 1/1 Running 0 12m 11.11.11.111 lab1kube-system kube-controller-manager-lab1 1/1 Running 0 12m 11.11.11.111 lab1kube-system kube-flannel-ds-amd64-4jrbk 1/1 Running 3 13m 11.11.11.112 lab2kube-system kube-flannel-ds-amd64-gvhs6 1/1 Running 0 13m 11.11.11.111 lab1kube-system kube-flannel-ds-amd64-kcpvr 0/1 CrashLoopBackOff 1 13m 11.11.11.113 lab3kube-system kube-proxy-4zdnc 1/1 Running 0 16m 11.11.11.111 lab1kube-system kube-proxy-7d59q 1/1 Running 3 14m 11.11.11.112 lab2kube-system kube-proxy-8w5gr 0/1 CrashLoopBackOff 1 14m 11.11.11.113 lab3kube-system kube-scheduler-lab1 1/1 Running 0 12m 11.11.11.111 lab1 [root@lab1 vagrant]# kubectl logs -n kube-system coredns-777d78ff6f-b7j8wstandard_init_linux.go:178: exec user process caused “operation not permitted” 解决方案https://github.com/rancher/rancher/issues/13310edit /etc/sysconfig/docker and remove –selinux-enabled from the OPTIONS variable]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>Devops</tag>
        <tag>Docker</tag>
        <tag>Centos7</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7搭建docker私有镜像中心]]></title>
    <url>%2F2018%2F12%2F14%2Fcentos7%E6%90%AD%E5%BB%BAdocker%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[安装Docker Registrysudo docker run -d -v /home/hzq/registry:/var/lib/registry -p 5000:5000 –restart=always –privileged=true –name registry registry:latest • -v /home/hzq/registry:/var/lib/registry 默认情况下，会将仓库存放于容器内的/var/lib/registry目录下，指定本地目录挂载到容器。• -p 5000:5000 端口映射• –restart=always1 在容器退出时总是重启容器,主要应用在生产环境• –privileged=true 在CentOS7中的安全模块selinux把权限禁掉了，参数给容器加特权，不加上传镜像会报权限错误OSError: [Errno 13] Permission denied: ‘/tmp/registry/repositories/liibrary’)或者（Received unexpected HTTP status: 500 Internal Server Error）错误• –name registry 指定容器的名称 查看版本 服务端需要修改的地方Docker从1.3.X之后，与docker registry交互默认使用的是https，然而此处搭建的私有仓库只提供http服务，所以当与私有仓库交互时就会报误。为了解决这个问题需要在启动docker server时增加启动参数为默认使用http访问。修改docker启动配置文件 vi /usr/lib/systemd/system/docker.service 找到 ExecStartExecStart=/usr/bin/dockerd –insecure-registry 192.168.0.153:5000红色字体为添加的如下图所示 重启dockersystemctl daemon-reloadsystemctl restart docker 客户端需要修改的地方编辑/etc/docker/daemon.json文件，添加”insecure-registries”:[“xxx.xxx.xxx.xxx:5000”] 重启dockersystemctl daemon-reloadsystemctl restart docker 登录到私有镜像中心docker login xx.xx.xx.xx:5000如图 上传镜像 拉取镜像 查看镜像仓库的镜像curl -XGET http://xx.xx.xx.xx:5000/v2/_catalog如下图所示 获取镜像仓库某个镜像的标签列表curl –XGET http://xx.xx.xx.xx:5000/v2/yyyy/tags/list 注：yyyy是镜像名称如图所示# 删除镜像Docker仓库在2.1版本中支持了删除镜像的API，但这个删除操作只会删除镜像元数据，不会删除层数据。在2.4版本中对这一问题进行了解决，增加了一个垃圾回收命令，删除未被引用的层数据。启动容器，此时不挂载config文件 进去容器，并查看/etc/docker/registry/config.yml文件，并复制文件内容 在宿主机，/home目录下新建config.yml文件，并将上一步复制的内容copy进去，而且添加允许删除停止之前启动的Registry，并删除，重新启动Registry，此时挂载config.yml文件，再次进入容器，可看到已添加delete=truesudo docker run -d -v /home/hzq/registry:/var/lib/registry –v /home/config.yml:/etc/docker/registry/config.yml -p 5000:5000 –restart=always –privileged=true –name registry registry:latest获取要删除指定镜像指定标签的Digest sha256curl -v –silent -H “Accept: application/vnd.docker.distribution.manifest.v2+json” -X GET http://11.11.11.116:5000/v2/app-auto-medical/manifests/v1 2&gt;&amp;1 | grep Docker-Content-Digesttag=v1 curl -v –silent -H “Accept: application/vnd.docker.distribution.manifest.v2+json” -X GET http://11.11.11.116:5000/v2/app-auto-medical/manifests/v2 2&gt;&amp;1 | grep Docker-Content-Digesttag=v2 curl -v –silent -H “Accept: application/vnd.docker.distribution.manifest.v2+json” -X GET http://11.11.11.116:5000/v2/app-auto-medical/manifests/v3 2&gt;&amp;1 | grep Docker-Content-Digesttag=v3 app-auto-medical镜像下的tag=v1、tag=v2的digest sha256值相同，与v3的digest sha256值不同删除指定标签指定镜像(仅是逻辑删除！如果同一个镜像下的多个tag的digest sha256值一样，则会一起被删除)删除之前可看到该镜像下有三个tag 也可以在浏览器直接查看 执行删除命令curl -v –silent -H “Accept: application/vnd.docker.distribution.manifest.v2+json” -X DELETE http://11.11.11.116:5000/v2/app-auto-medical/manifests/sha256:09873e1ff2a995777f646aef95efd11d08ce0dc95e33cd5e6c1ac8b33dfc30ae 删除后查看该镜像下边的tag情况 因为此镜像的tag v1和v2的digest sha256值相同，所以删除的时候就会被一起删除，但此时都只是逻辑删除，对应的文件资源并没有在磁盘上删除！ 垃圾回收垃圾回收前，查看Registry镜像资源数据大小，因为镜像资源所在目录已经被挂载到宿主机/home/hzq/registry目录，所以查看宿主机此目录的大小du -sch /home/hzq/registry 进入镜像仓库容器，进行垃圾回收(2.4版本以上的registry才有此功能)docker exec -it d78b4c6f2f81 /bin/registry garbage-collect /etc/docker/registry/config.yml 再次查看Registry镜像资源数据大小]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Devops</tag>
        <tag>Docker</tag>
        <tag>Register</tag>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Devops搭建手冊]]></title>
    <url>%2F2018%2F12%2F13%2FDevops%E6%90%AD%E5%BB%BA%E6%89%8B%E5%86%8A%2F</url>
    <content type="text"><![CDATA[Gitlab安装安装命令dpkg --force-depends -i gitlab-ce_10.3.3-ce.0_amd64.deb 备份/etc/gitlab/gitlab.rb文件cp gitlab.rb gitlab.rb.bak 修改/etc/gitlab/gitlab.rb文件external_url &quot;http://gitlab.example.com&quot; 为 external_url &quot;http://ip地址&quot; 使修改生效sudo gitlab-ctl reconfigure 默认root账号，需添加密码访问urlip:端口号(默认80) Nexus安装创建文件夹cd /usr/localmkdir nexus 下载Nexus安装包，并解压文件wget https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.14.8-01-bundle.tar.gztar -xzvf nexus-2.14.8-01-bundle.tar.gz -C nexus 添加root用户vi /usr/local/nexus/nexus-2.14.8-01/bin/nexus添加 RUN_AS_USER=root保存以上修改。备注：修改前请先备份原始文件 启动Nexus/usr/local/nexus/ nexus-2.14.8-01/bin/nexus start 访问Nexusip:端口号(默认8081)/nexus 默认Nexus账号密码admin admin123 注意：下载Nexus安装包的过程可以在本机操作，然后把安装包通过FTP上传到服务器上。存储所在路径：压缩包解压后，文件夹内nexus-2.14.8-01-bundle/sonatype-work/，这个路径就是，具体存储路径可以在nexus-2.14.8-01/conf/ nexus.properties文件里进行修改。参考：https://www.linuxidc.com/Linux/2016-08/134617.htm Docker安装FTP上传Docker的deb安装文件比如上传到此目录下：/tmp/docker-ce_17.12.1_ce-0_ubuntu_amd64.deb 更新库，安装依赖apt-get updateapt-get install -y apt-utils iptables libdevmapper1.02.1 libltdl7 libseccomp2 安装Dockerdpkg -i /tmp/docker-ce_17.12.1_ce-0_ubuntu_amd64.deb 验证安装是否成功docker –version如下图，显示docker版本号则安装成功 Kubectl安装下载kubectl安装包wget https://dl.k8s.io/v1.9.3/kubernetes-client-linux-amd64.tar.gz 解压kubectl安装包tar -zxvf kubernetes-client-linux-amd64.tar.gz 进入到kubernetes/client/bin目录，并给kubectl文件赋权限cd kubernetes/client/binchmod +x ./kubectl 移动kubectl文件到/usr/local/bin/目录下sudo mv ./kubectl /usr/local/bin/kubectlsudo chmod +x /usr/local/bin/kubectl 创建.kube文件夹mkdir ~/.kube 创建config文件touch ~/.kube/config K8S的配置信息通过token添加配置信息首先：web登录到ICP 其次：复制token信息 最后：在服务器命令行执行token信息里的命令，执行完之后步骤6里的config文件里会保存有k8s的相关配置信息，但是token是有实效期的。 通过证书添加配置信息首先：向ICP管理员要三个证书，三个证书在ICP的master节点上的路径为/etc/cfc/conf/，三个证书为：ca.crt，kubecfg.crt，kubecfg.key，将三个证书存放到/etc/kubernetes/conf/目录下，如果没有请创建该目录其次：执行kubectl命令，修改config文件。kubectl config set-cluster mycluster.icp –server=https://10.8.154.198:8001 –certificate-authority=/etc/kubernetes/conf/ca.crt \&amp;&amp; kubectl config set-credentials admin –client-certificate=/etc/kubernetes/conf/kubecfg.crt –client-key=/etc/kubernetes/conf/kubecfg.key \&amp;&amp; kubectl config set-context icp –cluster=mycluster.icp –user=admin \&amp;&amp; kubectl config use-context icp \&amp;&amp; kubectl config view 下载地址：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.9.md​ 参考：​ http://blog.csdn.net/farYang/article/details/79427573​ http://blog.csdn.net/weiguang1017/article/details/69972015​ 注意：1.压缩包里只有一个kubectl文件，1,、2、3、4步已经安装好kubectl了，只是不能与k8s通讯。2.证书配置是针对管理员的，普通用户用token3.修改host文件.如：10.8.154.198 mycluster.icp 7步骤b)中的–server= https://10.8.154.198:8001要进行修改 Jenkins安装向ICP管理员索要四个证书，master三个证书，私有镜像中心一个证书。如下图所示： 将master的上个证书存放到：/etc/kubernetes/conf/将私有镜像中心的证书存放到：/etc/docker/certs.d/mycluster.icp:8500/ 注意：证书原始路径，在ICP的master节点上​ Master证书路径：/etc/cfc/conf/ca.crt/etc/cfc/conf/kubecfg.crt/etc/cfc/conf/kubecfg.key​ 私有镜像中心证书路径：/etc/docker/certs.d/mycluster.icp\:8500/ca.crt 向ICP管理员询问cluster_vip、cluster_CA_domain、proxy_vip、storageClassName的值cluster_vip：页面访问ICP的IP地址​ cluster_CA_domain：私有镜像中心域名​ proxy_vip：代理的vip，用于应用的映射​ storageClassName：PVC的时候使用 修改服务器的hosts文件，添加私有镜像中心的映射，如下图所示 在k8s集群内新建devops命名空间命令：kubectl create ns devopsICP页面创建： 根据应用的场景创建java-slave,nodejs-slave等jenkins的slave镜像从docker-hub上下载openjdk、nginx、jenkins等镜像上传5、6步骤里的镜像到ICP的私有镜像中心如何上传，请参考ICP官方文档：https://www.ibm.com/support/knowledgecenter/en/SSBS6K_2.1.0/manage_images/using_docker_cli.html 创建secretkubectl create secret docker-registry myregistrykey –docker-server=mycluster.icp:8500 –docker-username=admin –docker-password=admin --docker-email=shuaichao_gao@trtjk.com -n=devops在jenkins的yaml里添加对该secret的引用 执行jenkins、pvc等yaml文件kubectl apply -f jenkins-master-sts-dev-test.yamlkubectl apply -f jenkins-slave-glusterfs-pvc.yaml 查看jenkins的状态#查看pod状态kubectl get pods -n=devops #查看pod详细描述信息kubectl describe pods -n=devops #查看应用的日志kubectl logs -f pods -n=devops 浏览器访问jenkins，按需安装必要插件在gitlab服务器修改hosts文件，添加jenkins应用的映射 注意Gitlab、Nexus、Docker、Kubectl都是安装在ubuntu服务器上的，jenkins是安装在ICP上的。各个软件的安装包和文件已打包证书与ICP环境是对应的，不同的ICP环境证书是不一样的。]]></content>
      <categories>
        <category>Devops</category>
      </categories>
      <tags>
        <tag>Devops</tag>
      </tags>
  </entry>
</search>
